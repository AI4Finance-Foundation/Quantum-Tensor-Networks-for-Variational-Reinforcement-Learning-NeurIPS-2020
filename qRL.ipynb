{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['http_proxy'] = \"http://127.0.0.1:12639\" \n",
    "os.environ['https_proxy'] = \"http://127.0.0.1:12639\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pkbar\n",
    "import time\n",
    "import random\n",
    "\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import matrix_product_state\n",
    "from tensorly.mps_tensor import mps_to_tensor\n",
    "from tensorly.base import unfold, fold\n",
    "tl.set_backend('pytorch')\n",
    "\n",
    "import tensornetwork as tn\n",
    "from tensornetwork import contractors\n",
    "backend = 'pytorch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mask(length, ratio=0.7):\n",
    "    keep = []\n",
    "    while len(keep) < int(ratio * length):\n",
    "        keep.append(random.randint(0, length - 1))\n",
    "        keep = list(set(keep))\n",
    "    return keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s, a = 25, 4\n",
    "\n",
    "# states: scan from left to right\n",
    "# actions: left, right, top, down\n",
    "\n",
    "R = torch.zeros((s, a)) \n",
    "for i in range(s):\n",
    "    if i % 5 == 0:\n",
    "        R[i, 0] = -1\n",
    "    if (i - 4) % 5 == 0:\n",
    "        R[i, 1] = -1\n",
    "    if i in range(5):\n",
    "        R[i, 2] = -1\n",
    "    if i in range(s - 5, s):\n",
    "        R[i, 3] = -1\n",
    "R[1, :] = 10\n",
    "R[3, :] = 5\n",
    "\n",
    "R_vec = R.reshape(s * a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s_t, a, s_(t+1)\n",
    "P = torch.zeros((s, a, s)) \n",
    "for i in range(s):\n",
    "    if i % 5 == 0:\n",
    "        P[i, 0, i] = 1\n",
    "    if (i - 4) % 5 == 0:\n",
    "        P[i, 1, i] = 1\n",
    "    if i in range(5):\n",
    "        P[i, 2, i] = 1\n",
    "    if i in range(s - 5, s):\n",
    "        P[i, 3, i] = 1    \n",
    "\n",
    "    for j in range(s):\n",
    "        if j == i - 1:\n",
    "            P[i, 0, j] = 1\n",
    "        if j == i + 1:\n",
    "            P[i, 1, j] = 1\n",
    "        if j == i - 5:\n",
    "            P[i, 2, j] = 1\n",
    "        if j == i + 5:\n",
    "            P[i, 3, j] = 1\n",
    "    if i == 1:        \n",
    "        P[i, :, :] = 0\n",
    "        P[i, :, 21] = 1\n",
    "    if i == 3:\n",
    "        P[i, :, :] = 0\n",
    "        P[i, :, 13] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_mat = torch.empty((s, a, s, a))\n",
    "for ss in range(s):\n",
    "    for i in range(a):\n",
    "        P_mat[:, :, ss, i] = P[:, :, ss]\n",
    "P_mat = P_mat.reshape(s * a, s * a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.tensor(\n",
    " [[21.97748529, 24.4194281, 21.97748529, 19.4194281, 17.47748529],\n",
    " [19.77973676, 21.97748529, 19.77973676, 17.80176308, 16.02158677],\n",
    " [17.80176308, 19.77973676, 17.80176308, 16.02158677, 14.4194281],\n",
    " [16.02158677, 17.80176308, 16.02158677, 14.4194281, 12.97748529],\n",
    " [14.4194281, 16.02158677, 14.4194281, 12.97748529, 11.67973676]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class K_Spin(object):\n",
    "    \n",
    "    def __init__(self, s_size, a_size, k, data=None):\n",
    "        '''\n",
    "        args: \n",
    "            s_size: the cardinality of the state space\n",
    "            a_size: the cardinality of the action space\n",
    "            k: the number of interacting states\n",
    "        '''\n",
    "        super(K_Spin, self).__init__()\n",
    "        self.k = k\n",
    "        self.s_size = s_size\n",
    "        self.a_size = a_size\n",
    "        \n",
    "        if data is not None:\n",
    "            self.leaf = data\n",
    "        else:\n",
    "            self.leaf = torch.randn((s_size * a_size, 1))\n",
    "            self.leaf.requires_grad = True\n",
    "                \n",
    "        self.data = self.softmax_by_state()\n",
    "        self.qubits = self.create_qubits()\n",
    "        self.outer_product_chain()\n",
    "\n",
    "    \n",
    "    def softmax_by_state(self):\n",
    "        '''\n",
    "        returns:\n",
    "            updated data tensor after doing a softmax operation\n",
    "            with regard to each of the states\n",
    "        '''\n",
    "        states = []\n",
    "        softmax = torch.nn.Softmax(dim=0)\n",
    "        for s in range(self.s_size):\n",
    "            state = self.leaf[s * self.a_size : (s+1) * self.a_size, :]\n",
    "            states.append(softmax(state))\n",
    "        return torch.cat(states, dim=0)\n",
    "        \n",
    "        \n",
    "    def outer_product_chain(self):\n",
    "        '''\n",
    "        modifies:\n",
    "            connects the qubits into a tensor network that\n",
    "            computes the outer product when contracted\n",
    "        '''\n",
    "        if self.k == 1:\n",
    "            return\n",
    "        self.qubits[0][1] ^ self.qubits[1][1]\n",
    "        for k in range(1, self.k - 1):\n",
    "            self.qubits[k][2] ^ self.qubits[k + 1][1]\n",
    "\n",
    "\n",
    "    def create_qubits(self):\n",
    "        '''\n",
    "        returns:\n",
    "            a list of qubits (nodes) with suitable dimensions\n",
    "            (may contain dummy dimensions)\n",
    "        '''\n",
    "        qubits = []\n",
    "        backend = 'pytorch'\n",
    "        for i in range(self.k):\n",
    "            if i == 0 or i == self.k - 1:\n",
    "                q = tn.Node(self.data, backend=backend)\n",
    "            else:\n",
    "                q = tn.Node(self.data.unsqueeze(-1), backend=backend)\n",
    "            qubits.append(q)\n",
    "        return qubits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_H(k, P, R, s, a, mask, gamma=0.9):\n",
    "    \n",
    "    h = torch.zeros([s * a] * k, dtype=torch.float32)\n",
    "    \n",
    "    pbar = pkbar.Pbar(name='initialize H, k='+str(k), target=(s * a))\n",
    "    for i in range(s * a):\n",
    "        pbar.update(i)\n",
    "        in_edge = torch.sum(P[..., i // a])\n",
    "        \n",
    "        if k == 1:\n",
    "            if i in mask:\n",
    "                h[i] = 1\n",
    "\n",
    "        if k == 2:\n",
    "            for j in range(s * a):\n",
    "                if i in mask and j in mask:\n",
    "                    h[i, j] = P_mat[i, j]\n",
    "                \n",
    "        if k == 3:\n",
    "            for j in range(s * a):\n",
    "                for l in range(s * a):\n",
    "                    if i in mask and j in mask and l in mask:\n",
    "                        h[i, j, l] = P_mat[i, j] * P_mat[j, l]\n",
    "                    \n",
    "        if k == 4:\n",
    "            for j in range(s * a):\n",
    "                for l in range(s * a):\n",
    "                    for m in range(s * a):\n",
    "                        if i in mask and j in mask and l in mask and m in mask:\n",
    "                            h[i, j, l, m] = P_mat[i, j] * P_mat[j, l] * P_mat[l, m]\n",
    "                        \n",
    "        h[i, ...] *= in_edge\n",
    "        \n",
    "    for n in range(s * a):\n",
    "        h[..., n] *= R_vec[n]\n",
    "        \n",
    "    h.requires_grad = False\n",
    "    return tn.Node(h * gamma ** (k - 1), backend=backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block(*dimensions):\n",
    "    ''' \n",
    "    returns:\n",
    "        a new matrix for the MPS with random numbers from 0 to 1 \n",
    "    '''\n",
    "    size = tuple([x for x in dimensions])\n",
    "    return torch.randn(size)\n",
    "\n",
    "\n",
    "def random_mps(rank, dim, bond_dim=20):\n",
    "    '''\n",
    "    returns\n",
    "        a set of randomly initialized tensor cores connected in MPS\n",
    "        a set of connected edges\n",
    "    '''\n",
    "    if rank == 1:\n",
    "        return [tn.Node(block(dim), backend=backend)], []\n",
    "\n",
    "    head = [tn.Node(block(dim, bond_dim), backend=backend)]\n",
    "    mid = [tn.Node(block(bond_dim, dim, bond_dim), backend=backend) for _ in range(rank-2)]\n",
    "    tail = [tn.Node(block(bond_dim, dim), backend=backend)]\n",
    "\n",
    "    mps = head + mid + tail\n",
    "    \n",
    "    # connect edges to build mps\n",
    "    connected_edges=[]\n",
    "    conn = mps[0][1] ^ mps[1][0]\n",
    "    for k in range(1, rank-1):\n",
    "        conn = mps[k][2] ^ mps[k+1][0]\n",
    "        connected_edges.append(conn)\n",
    "\n",
    "    return mps, connected_edges\n",
    "\n",
    "\n",
    "def put_mps(tensors):\n",
    "    '''\n",
    "    returns\n",
    "        a set of tensor cores connected in MPS\n",
    "        a set of connected edges\n",
    "    '''\n",
    "    mps = []\n",
    "    for i in range(len(tensors)):\n",
    "        mps.append(tn.Node(tensors[i].detach().clone(), backend=backend))\n",
    "    \n",
    "    if len(tensors) == 1:\n",
    "        return mps, []\n",
    "    \n",
    "    connected_edges=[]\n",
    "    conn = mps[0][1] ^ mps[1][0]\n",
    "    for k in range(1, len(tensors)-1):\n",
    "        conn = mps[k][2] ^ mps[k+1][0]\n",
    "        connected_edges.append(conn)\n",
    "\n",
    "    return mps, connected_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_permutation(tensor, i):\n",
    "    shape = [tensor.shape[l] for l in range(i, len(tensor.shape))] + \\\n",
    "            [tensor.shape[m] for m in range(i)]\n",
    "    perm = torch.empty(shape)\n",
    "    for j in range(tensor.shape[i]):\n",
    "        perm[j, ...] = torch.index_select(tensor, i, torch.tensor([j])).squeeze()\n",
    "    return perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_grad_complete(mps, target, omega, lr=0.1, epochs=10000):\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    op = optim.SGD(mps, lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "    for e in range(epochs):\n",
    "        op.zero_grad()\n",
    "        loss = criterion(omega * mps_to_tensor(mps), omega * target)\n",
    "        loss.backward()\n",
    "        print(loss)\n",
    "        op.step()\n",
    "    return mps\n",
    "\n",
    "def tensor_als(mps, target, omega, lr=0.1, epochs=10000):\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    for e in range(epochs):\n",
    "        for i, core in enumerate(mps):\n",
    "            X = unfold(tensor_permutation(target), i)\n",
    "            B = \n",
    "            for j in range(core.shape[1]):\n",
    "                core[:, j, :] = X[j, :] @ torch.inverse()\n",
    "    return mps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_dims(tensor, dim):\n",
    "    N = tensor.shape[0]\n",
    "    order = len(tensor.shape)\n",
    "    if order == dim:\n",
    "        return tensor\n",
    "    pad = torch.zeros([N] * dim, dtype=torch.float32)\n",
    "    for i in range(N ** order):\n",
    "        index = np.unravel_index(i, tensor.shape)\n",
    "        pad[index] = tensor[index]      \n",
    "    return pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize omega\n",
      "100/100  [==============================] - 294.0s\n"
     ]
    }
   ],
   "source": [
    "k = 4\n",
    "s, a = 25, 4\n",
    "chi = 10\n",
    "mask_vec = random_mask(100, 0.7)\n",
    "\n",
    "pbar = pkbar.Pbar(name='initialize omega', target=s * a)\n",
    "omega = torch.zeros([s * a] * k, dtype=torch.float32)\n",
    "for i in range(s * a):     \n",
    "    pbar.update(i)\n",
    "    for j in range(s * a):\n",
    "        for l in range(s * a):\n",
    "            for m in range(s * a):\n",
    "                if i in mask_vec and j in mask_vec and l in mask_vec and m in mask_vec:\n",
    "                    omega[i, j, l, m] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize H, k=1\n",
      "100/100  [==============================] - 0.1s\n",
      "initialize H, k=2\n",
      "100/100  [==============================] - 0.2s\n",
      "initialize H, k=3\n",
      "100/100  [==============================] - 6.0s\n",
      "initialize H, k=4\n",
      "100/100  [==============================] - 592.7s\n"
     ]
    }
   ],
   "source": [
    "mode = 'combined_TT' \n",
    "gamma = 0.975\n",
    "data = torch.randn((s * a, 1), requires_grad=True)\n",
    "    \n",
    "H = []\n",
    "H_core = []\n",
    "H_list = []\n",
    "\n",
    "if mode == 'full':\n",
    "    for i in range(k):\n",
    "        H.append(initialize_H(i + 1, P, R, s, a, mask_vec, gamma=gamma))\n",
    "        H_core.append([H[i]])\n",
    "    \n",
    "if mode == 'combined_TT':\n",
    "    for i in range(k):\n",
    "        H.append(initialize_H(i + 1, P, R, s, a, mask_vec, gamma=gamma))\n",
    "        tensor = H[-1].get_tensor()\n",
    "        if len(tensor.shape) > 1:\n",
    "            H_list = matrix_product_state(tensor, chi)\n",
    "            H_list[0] = H_list[0].squeeze(0)\n",
    "            H_list[-1] = H_list[-1].squeeze(-1)\n",
    "        else:\n",
    "            H_list = [tensor]\n",
    "\n",
    "        # tensors = tensor_als(tensors, H, omega)\n",
    "        H_nodes, conn = put_mps(H_list)\n",
    "        H_core.append(H_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-117-a9aba965073c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_leaf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mC_cores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor_als\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC_cores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0momega\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-111-16b1a3390451>\u001b[0m in \u001b[0;36mtensor_als\u001b[1;34m(mps, target, omega, lr, outer_epochs, epochs)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0momega\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmps_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0momega\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \"\"\"\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "C = H[1].get_tensor()\n",
    "C_cores = matrix_product_state(C, chi)\n",
    "for c in C_cores:\n",
    "    c.requires_grad = True\n",
    "    print(c.is_leaf)\n",
    "C_cores = tensor_als(C_cores, C, omega, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress\n",
      "10000/10000  [==============================] - 88.2s\n"
     ]
    }
   ],
   "source": [
    "lr = 0.00001\n",
    "energy_history = []\n",
    "epochs = int(1e4)\n",
    "Pbar = pkbar.Pbar(name='progress', target=epochs)\n",
    "\n",
    "op = optim.SGD([data], lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "for e in range(epochs):\n",
    "    spins = []\n",
    "    core = []\n",
    "    edge = []\n",
    "    energy = 0\n",
    "    op.zero_grad()\n",
    "    \n",
    "    for i in range(k):\n",
    "        core.append(tn.replicate_nodes(H_core[i]))\n",
    "        edge.append([])\n",
    "        for j in range(len(core[i])):\n",
    "            edge[i] += core[i][j].get_all_dangling()\n",
    "    \n",
    "    for i in range(k):\n",
    "        spins.append(K_Spin(s, a, i + 1, data=data))\n",
    "        for j in range(i + 1):\n",
    "            edge[i][j] ^ spins[i].qubits[j][0]\n",
    "            \n",
    "    for i in range(k):\n",
    "        energy -= contractors.branch(tn.reachable(core[i]), nbranch=1).get_tensor()\n",
    "    energy.backward()\n",
    "    energy_history.append(energy)\n",
    "    \n",
    "    op.step()\n",
    "    Pbar.update(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# with plt.style.context(['science', 'notebook']):\n",
    "plt.plot(energy_history)\n",
    "plt.title='Policy Iteration using K-Spin Hamiltonian'\n",
    "plt.xlabel='Number of iterations'\n",
    "plt.ylabel='Energy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = spins[0].data.reshape(s, a).detach().numpy()\n",
    "ax = sns.heatmap(result, cmap=\"Blues\")\n",
    "plt.xlabel = 'States'\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 0., 3., 0.],\n",
       "        [3., 1., 2., 2., 2.],\n",
       "        [2., 2., 3., 3., 2.],\n",
       "        [1., 1., 0., 2., 0.],\n",
       "        [3., 0., 1., 3., 2.]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = torch.empty(s)\n",
    "p = torch.tensor(result)\n",
    "for i in range(s):\n",
    "    policy[i] = torch.argmax(p[i, :])\n",
    "policy.reshape(5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x166c07170c8>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(target, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
